{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac475a47-6f25-4bf9-be9b-84135af81db8",
   "metadata": {},
   "source": [
    "# Answer 1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "attachments": {
    "22238882-4f6f-4fcb-bb26-23d620a282a4.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAIzSURBVDhP7ZU/aBNRHMc/ilxATBHMlBhJUAwZahxyFIwdKkKjDln8s2QxCuVoMQgSl4hDFGkG6RU0FvWGWqQkkxEkgjSDRpC4tAXNuaQQeoKQKcU/AdGXuwtoTbLYTT/Dvft97/2+773fe3e3ze/3/2AL2W63W8Z/w79ngGGA2GSazJU4steWbAKjY39oXfoYRkgv5kgEHXiOJ5m5mbR1wcks6u0s6YlhW/idnobuywpHPxdQpnS+SiDtctFNl0cD7KHFur5qK6J/eIxI0LrvaRjdL1F7kcO4eIyQE4x3RbrpR/a54buB/sgWSJDOZslMnjGjHeZ1E9rUWbNN3A8gYbDytGrGoBDaKxqjTsESBBrqdR1eVsxowKbECYuZ8lGn+MaWzg3j2wnNtYoYxqKzQUMiFpYmAwx9uMRyW+srdOcnH/bgpI2hl0TkJq4ucPW0wvSCJhZuMcBwE94458Od+tVZnhPxiEJUWiKx1haDgMPsNNBQE0tt4jwUJ7+Y54mmIO8WcqNm1c8oos6WSIUDtD+8ItfRBP0Ng37qd6LEktNo8zluzC+LwyJ89OdW/RpVqhsJwgebVIslZGHcobfhSJr8gxlmZu8SeVum9GyD8VMhnG2dpbluRUVNJ2T8zRrlTwrJCxFT623oc+OS2jRXX1MRr2BCzXDC26JyL4XasPt0+PJNbNEQ45c81B5rptTnix0hmUsRO+AQCZ2jU+HhrWsU3tuPf8E6NmWq9kD/3C8AfgKwGawqJvRvqwAAAABJRU5ErkJggg=="
    },
    "23900c44-5df6-4914-9634-bf21f37b0b2c.png": {
     "image/png": "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"
    },
    "36b1fd2d-305f-46b9-8001-67a8bc063ce2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABEAAAAXCAYAAADtNKTnAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF5SURBVDhP7ZQxSMNAGIWfDg6iU8Ah0uEWIwEzNTiEghaHUKhdlC5OXaQiUqF0q4I6FRGd6tTFLOpUhFJB6NIO0oCQgrRdnKwguCgIuuglF6lNk3ToJPgtL/cOvoQ/x40QQr4wJKN2DsUfkAghFWpIsFf+eEhkqPEkMkca6uVjrNmtFx6SOk42YyjobwCnQN22aw98Z6KVDLzQFIIZ8KxyxX+wVxU0TctMEIkAq9zwl6CI8r1pIZDXZVa5MEAClM8NdGjy4jIdtzsDJbi9ROuJZkDC6jyrnAyUKFtJSFPmEw8prlqdE1+JktawH59AdbeIB7rmRBUxttWDp0TZuUBuhUfzNIWD6wL0Ni25WSxG2f5vXCWWIDqNx1IWG2fmWDvQ7lo0OUiR/vPbJ2ECgg89j9RezW6p5rCGxjswKYaRsLsfeiULOWRNQUNDNqlZv7ZLHtX2JzA+h3C69/w6bjYe8hLB600N5sf3I0CJEIw9G6jo3Vf8X49OgG+gJV7F/k40igAAAABJRU5ErkJggg=="
    },
    "91cfdbff-db37-4f69-a56c-b929be32302e.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABMAAAAgCAYAAADwvkPPAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAKoSURBVEhL7ZZPSJNxHIefMhyB86IUvCL4pqAe6qJj4E5TwxXU6LA6ZEFh0CxqRO2iJqQW7bS3yzrEDrVL7tIQbIfQQHeQCZFC9kKoEL1CbBDtNCHq3bufvu9yisKOPpd33+/77tnvz+fHuyOyLP+lQhwV14pwKDs4FZXtHY1GB/1XLtJqz6FOxYgtauJGeXYdWetAmMTLR3TVFaomfEqcyccu495ulB/ZhTDJO9XEbg0S+15s9UdmuN/yldDZQeLF1g7KjMxL+LbM0oQp2qYKbOJjOXbKBry0aQmCc6I28NIp29ncUJkRnXIcE9dt/F0S2kIU2l14dAG5NXLuqzjsa7yfUNhrC/6T+Th9MsNnNUTitRtJdHUj6Rf9jJeMdiel03Q6aMivEf8YJPhghJHREQLXvUSXbTgu+XGIx6xInW7cncWfLZX1NmFbTxlTUeeSJKeTpFY0Ius/9MydwecsPmbiY/hZiPF7PqMqkfmba1n9lBSViVRV2EM7NU3F2iSO8iRIYEgxKousuF7qG1Fa8LXo0/ijob4VDQMJR6+H+swsaREhU1ZYr+O/yYpyG+cwrmbY/JKyhNXFcDTMjZ7LjLyaZFhM35Tp6yXZ2+i6Zu4hjR7GHp5D/pUmMhrZjoVj3M+phQCD7zLkq2upN46c5Tj5o0kc6jw1fd3YfuoP6b3aE/Xk1QSRpwpJy2mQ2lthRUUbmiTdk0Hp1k+L3hc5E/m6OY7yPI7rvIx9M8vSh3TZkGq6qIC/uQE2UoaoQHGaW/kyCpWUHonkLiITD61SNdo3cyWLMku+9o2zG7kuy9qC+S1D5tE187M787UXUp++YblVFqdFQ+dgL2HnGAnFQ34qgNoRwqVF6L67tWLWaOyLDNlcFltHEHk5jN8iKnD49+DgVFAG/wCSKdkVPSVsZgAAAABJRU5ErkJggg=="
    },
    "a16fdd70-88e8-4dc7-9581-991e2a6397d7.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABEAAAAXCAYAAADtNKTnAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF5SURBVDhP7ZQxSMNAGIWfDg6iU8Ah0uEWIwEzNTiEghaHUKhdlC5OXaQiUqF0q4I6FRGd6tTFLOpUhFJB6NIO0oCQgrRdnKwguCgIuuglF6lNk3ToJPgtL/cOvoQ/x40QQr4wJKN2DsUfkAghFWpIsFf+eEhkqPEkMkca6uVjrNmtFx6SOk42YyjobwCnQN22aw98Z6KVDLzQFIIZ8KxyxX+wVxU0TctMEIkAq9zwl6CI8r1pIZDXZVa5MEAClM8NdGjy4jIdtzsDJbi9ROuJZkDC6jyrnAyUKFtJSFPmEw8prlqdE1+JktawH59AdbeIB7rmRBUxttWDp0TZuUBuhUfzNIWD6wL0Ni25WSxG2f5vXCWWIDqNx1IWG2fmWDvQ7lo0OUiR/vPbJ2ECgg89j9RezW6p5rCGxjswKYaRsLsfeiULOWRNQUNDNqlZv7ZLHtX2JzA+h3C69/w6bjYe8hLB600N5sf3I0CJEIw9G6jo3Vf8X49OgG+gJV7F/k40igAAAABJRU5ErkJggg=="
    },
    "bed313bb-ccfd-49f3-8c55-f8826b2bde92.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABMAAAAdCAYAAABIWle8AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAJ1SURBVEhL7ZVPSJNhHMc/RUyIJkGeZoajaHkwO+xFaHlQAq0gL/059F56DeRFaRRihxYdVoQ7xCbkFOs9mIRsJxfEgnCHWhDrokLt7aIwfINgJ6U/A6ln27PUbWWBHaI+l2e/7/u8n/d9fs/zsm1Op/MrW8R2OW4Jf7XMgaNB/tyETWQefFNRoqNB1F8Q/kQmRNEAHavTRMxD6OMjmwp/KGu+3oOSCaNeCBC6quFP1HJ64Ky8Wp0/fc5cdPf58A+oKGXLcrW1V2TrKZPlGx5Ga6qh/riX4G2vzAUnxXLvBvD1Nsugkg0yxxWdYx+j6P0mn21g21VH6ValzcUellky52Ui5rvb8TTJQrBB1rXfRvpZGOtSBy12sN7EKN16dJ8DVi3MhzJAwxcI4O9b25Qdcixg9J8rjNq4CxsWc49ThRp0WvaKwVogWgwEBqGbJjxPyrrqBqi4xRvy3iT2Skbnm2ncCdnFpHhEkfxm1Ipa6L5TRdZInVji8tIcpfdSjtRjJ4dlxkXlQA1Ncu2MztCkIRa7RhVZGQ0qF935fi0wOybqVp0u2wzaYk48AGoKk4pUkRlieVnsh1UiUxGmDR1lt4gz6WK/rBih4TiDbhe5dy8I5zNJpazJycK9Lrq9QxgTYW5NzIoDIRzm02K/MilSKxrug1lSsTiKkJbYKGv1EbkfJDg8gud1gviTFTpPtWDPmcyMlTooetir4MymSXzQ8fZ4ZFoua3RQZ8uRnX9JUnxWWsjPiYZlkqODhDJyTp5PX8R21NJ5uZ70I0OGFR+6B294kO4DNWJy/ngkeXDnBtG38vI6ikcjQWrdQ/7/O/0+/4QMvgGLd8Ghl1ihvAAAAABJRU5ErkJggg=="
    },
    "f6b70550-5103-4746-8d65-4bb43df30888.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c3b69cd2-ad40-4bb5-ae8c-c10858acbb55",
   "metadata": {},
   "source": [
    "Ridge regression, also known as Tikhonov regularization, is a linear regression technique that adds a penalty term to the ordinary least squares (OLS) regression loss function to prevent overfitting. It addresses the issue of multicollinearity and reduces the variance of the coefficient estimates.\n",
    "\n",
    "Here's how Ridge regression differs from ordinary least squares (OLS) regression:\n",
    "\n",
    "1. **Penalty Term:**\n",
    "   - In OLS regression, the objective is to minimize the sum of squared residuals between the observed and predicted values of the dependent variable.\n",
    "   - In Ridge regression, a penalty term is added to the OLS loss function. The penalty term is the squared sum of the coefficients multiplied by a regularization parameter ![image.png](attachment:36b1fd2d-305f-46b9-8001-67a8bc063ce2.png), known as the ridge parameter or regularization strength.\n",
    "\n",
    "2. **Objective Function:**\n",
    "   - OLS Regression Objective Function: ![image.png](attachment:f6b70550-5103-4746-8d65-4bb43df30888.png)\n",
    "   - Ridge Regression Objective Function: ![image.png](attachment:23900c44-5df6-4914-9634-bf21f37b0b2c.png)\n",
    "     where:\n",
    "     - ![image.png](attachment:22238882-4f6f-4fcb-bb26-23d620a282a4.png) is the observed value of the dependent variable for observation \\( i \\).\n",
    "     - ![image.png](attachment:bed313bb-ccfd-49f3-8c55-f8826b2bde92.png) is the predicted value of the dependent variable for observation \\( i \\).\n",
    "     - ![image.png](attachment:91cfdbff-db37-4f69-a56c-b929be32302e.png) are the coefficients of the predictors.\n",
    "     - ![image.png](attachment:a16fdd70-88e8-4dc7-9581-991e2a6397d7.png) is the regularization parameter, which controls the strength of regularization.\n",
    "\n",
    "3. **Effect on Coefficients:**\n",
    "   - OLS regression estimates the coefficients by minimizing the sum of squared residuals only. As a result, the coefficients may become large when there is multicollinearity in the predictors.\n",
    "   - Ridge regression penalizes large coefficients by adding the squared sum of the coefficients to the loss function. This penalty shrinks the coefficient estimates towards zero, reducing their variance. Ridge regression can effectively handle multicollinearity and stabilize the coefficient estimates.\n",
    "\n",
    "4. **Bias-Variance Trade-off:**\n",
    "   - OLS regression aims to minimize the bias in the coefficient estimates by fitting the data closely. However, this can lead to high variance in the coefficient estimates when there is multicollinearity.\n",
    "   - Ridge regression introduces a bias into the coefficient estimates by shrinking them towards zero. However, this bias reduces the variance of the estimates, resulting in more stable predictions overall. Ridge regression achieves a balance between bias and variance, leading to better generalization performance, especially when multicollinearity is present.\n",
    "\n",
    "In summary, Ridge regression differs from ordinary least squares (OLS) regression by adding a penalty term to the loss function, which helps prevent overfitting and stabilizes the coefficient estimates, particularly in the presence of multicollinearity. Ridge regression achieves a balance between bias and variance and is useful when multicollinearity is a concern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de0bc2-b004-4774-a110-1b1472adbb2f",
   "metadata": {},
   "source": [
    "# Answer 2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa44ac2-cb33-4ef6-b7ae-31b50d11acc1",
   "metadata": {},
   "source": [
    "Ridge regression, like ordinary least squares (OLS) regression, relies on several assumptions to provide valid and reliable estimates. These assumptions are essential for interpreting the results and making inferences about the relationships between variables. Here are the key assumptions of Ridge regression:\n",
    "\n",
    "1. **Linearity**: Ridge regression assumes that the relationship between the independent variables (predictors) and the dependent variable (outcome) is linear. This means that the effect of a one-unit change in the predictors is constant across all levels of the predictors.\n",
    "\n",
    "2. **Independence of Errors**: The errors (residuals) in Ridge regression should be independent of each other. In other words, there should be no systematic patterns or correlations among the residuals. Violations of this assumption can lead to biased coefficient estimates and incorrect inferences.\n",
    "\n",
    "3. **Homoscedasticity**: Ridge regression assumes that the variance of the errors is constant across all levels of the predictors. This means that the spread of the residuals should be the same for all values of the predictors. Heteroscedasticity, where the variance of the errors varies with the predictors, can lead to inefficient coefficient estimates and incorrect standard errors.\n",
    "\n",
    "4. **No Perfect Multicollinearity**: Ridge regression assumes that there is no perfect multicollinearity among the predictors. Perfect multicollinearity occurs when one predictor variable can be perfectly predicted by a linear combination of other predictor variables. While Ridge regression can handle multicollinearity to some extent, it cannot resolve issues of perfect multicollinearity.\n",
    "\n",
    "5. **Normality of Errors (Optional)**: While not strictly necessary for Ridge regression, the assumption of normality of errors may be relevant for inference and hypothesis testing. The errors are assumed to follow a normal distribution with a mean of zero. However, Ridge regression is relatively robust to deviations from normality, especially for large sample sizes.\n",
    "\n",
    "It's important to note that Ridge regression is less sensitive to violations of some assumptions, such as multicollinearity, compared to OLS regression. Ridge regression can provide more stable coefficient estimates and improved prediction accuracy, even when assumptions are not perfectly met. However, it's still essential to be aware of the underlying assumptions and assess their validity when interpreting the results of Ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45cbda-7c4e-4dc6-a2b0-4b14f37b5260",
   "metadata": {},
   "source": [
    "# Answer 3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "attachments": {
    "22b9e86b-89f7-411a-889c-f964c329174c.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "24f5e5e7-01d4-44c3-a4b4-5617b11c4c66.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "43ebaabe-c524-4d91-89e9-f3afd5e2a5c1.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "66a8fd8d-82d7-4afc-b2aa-82b2b2cca39d.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "78a67d7a-2ff1-4b4a-b604-a697e7f2022f.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAZCAYAAABHLbxYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAALfSURBVFhH7ZdPSJNhHMe//cEXgslCEXo1cCXMDs4CX4TGDorgS4eNDutg22WdtMgdch18JcpBsDpY5BYoK9gMch16i9a8bEHsIO8iqIteUhguGvPihjFB6nnng06313xrpoKfw57f833H837f5/n9ftt7RKfT/cIB4Cgd9z37wqje5IDrlgMdbSxVStljoyx6x0QMmxnMZVhc84iIPLERtZQ9Nkp28TyLem0eoeduRGazqGk3E7WUPTYaQ+RDHNGpSGGmYRhgOYdUYbaZslXPdrsgdGXQN+CnyhbOWSHctMBwsgrIziP2agS+qXLL7wy9iYfOYIbLfgYzow70BUrXWt9Rzu7C8CM/Jt9FIbqt4BoVEtskYHLcCS4XwYOBIUzM1sJ6NwivXbkQ/kSzwQhjA3nmxSXkGA1VN7O+o7JRc1MVUp8Z8IM82HkRnNVd+NIGHISQFxYmhj6zCxJVe/1xOFgJbt4JURbsIxCvNoMcpAJLkJ5ewdBrOqVw90V4uxjE7/FwvqUi5TgdIQU89MYCOgYLQSnt8k6TJ098WTcpIyYzcLQY0N1D4hdECDhhCaxd25aeYUxerkfisQOej8TDzzwRWbAXyLDFqLpiukgWoWExqVX5BhrUt3Brwk5p0kPXqIdBNkZgj8lnsIJcmXRXZ1RDimcbNFo9jXbIszeQvmeBswJp+B6MmFgsTvsgjNPrRagyajtVS6MKkQySXO+nHWMGPpcF/I1g2fakymh+lQYVZRbxsB+eh37EEsotTpXRUDpDo/+Puhz9kSOprkw2HaVR5VFnNPwNC2TQVNeszSm8tpp8LmJuWvno/hVlo6RVlLSiJMmjr2RPG1qL/jgY0dlEjCclTISptAts/NbfDiJ+SYeqE0UtaHUFK/kMJK8FzpdUO22Dd6wfrcsS3n9KobalE8a6FEJ3bIWmvVv85auIHpbrVrTVMcinEwiNiqR2d5fDd6ZKc2i00hwQo8BvH63WxYEwwbIAAAAASUVORK5CYII="
    },
    "94281279-13d3-4739-8869-3b9109931219.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "9bf5d4aa-885c-46b8-acdb-0b85c4ddb431.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABoAAAAaCAYAAACpSkzOAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAKFSURBVEhL7ZZBSNNRHMc/JWwkKsKEYDLYH6VR4S45PPzzkAiJh9bFHWodkg6NwFaHP2FpmLs0D9nB1iF2cYa2k0VoBFslC2QEoZAa5AJxkCyQ/iJsEPXcnuBo0ynMU5/L773v7w/f//u993u8I4qi/OEQOCpj2flvVCJmHBc9aDe6UE/mlDIYORkcD+A5nSaBivYsxot+tQxGl86jNpgxHZsnPOIlnjSgtF4ug9FMlOmPUSJv4mLioMYogv6Tf/vI0oHW20bKoxGUUh4i7+lxcc5SBZkUc68f45tYksltxB6127G2duNth6k7LrmiFjfawDDB8DSR8CBdzVbxaQEsbp4ERd60yNiAl6G3Gzh6gtk9yKce2xkVe20GfX2DTKV5Z+l0lt8FiCXltADu3m4cBlH7bj+TC0nioxq+DymUTnHCLPKjLHFCD/vou+lm8oeNrn6/NJoN4b/fh29kkvTvrFIAD22nqmFtmYBUtoh/WUWvsNF8NVcDxy2xwnE/bmmsp9NgyFvRHnTaMFfK8U7kj9VbndloO2FFabBjb8pOJfo+jGoNGOSwEIZqUzaGnkdIrP2iqlVDuxvEbTeSeLVdulJorEMUbm9mfLiuDxH+rMP6FIPXVFwPYvswKrp3BViJE50I4B8JE1vISaUbJVKi0gendKNvG7sa6anvclSY0o1m51jdcqquoyOn5Dhek9275NdQbl6EIkZGjHkNuEWIsVnRzSYFtUVK4v7wNCmwOU/kkZSKIO86jdB7J4pRHOEKmRFkNjOkPg3jvB2Wiso90YzO2gTRmUXS1rOiidPEn3rwju5ypQgO8DgRF+YVNxcaRcH0JV5OhIivyNQu/H8FHZhDMoK/YFvFBBKO2OgAAAAASUVORK5CYII="
    },
    "a0134b98-4430-4edf-9001-b1c8eb551421.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "a50ec0a8-03a8-467b-987d-6571d637df67.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "bdee2b2d-1acd-4fbb-bd76-1e6f7d5d2c57.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "da41f978-a4e2-4a8a-9452-4a4cc729cc9b.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "da6281bd-e44e-4274-8beb-e5be6d5dd086.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    },
    "f9db8634-a41f-4077-b140-9a57d2220e7c.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAVCAYAAABPPm7SAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF2SURBVDhP1ZQ/SAJhGIefGhqiJqHhwuGWDCEnj4ZDKGk4hHIpXJpcwogwEDcLqkkiarLJpVuqSQIxCFx0CIVAIdSlKYOgpSCope68C//dORQNPct73+/jffh47+MbEkXxk18wbNYf8zcCl09B8bnM1WAsBBJKKEL8UKWUO2LVTO2wEJQ43giSLr+CQ0bZMmMbbGegZis8a9XljSMYkSX2Q7zMU9MNU17CTiOywl5AhtydbhCR1iQjsmCAAHJnFZpaFdxL2mitGSjg5oL6o1adHlZmjaiXgQJ5M4JnQv8S8ISUVtaLrUCOqeyFxijsZLjX1g63QtDY6sJSIG+fk1wWqJ1E2b9KU25ooWOa+UVjv5M+Qat5cZKHbIL1U32ETdTbulYdeAL997JLYDSLvJdTRHeLZqopDopU32Dc7SdsZt+0BXNJEnpzVSURUVu/r02KQuMDRmfwx7rvZceDIiAtiLxcF9EP3I8LOSAy8lQhX27r//2LBF9ViF7BV9hFWwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "bb5837b0-0dc0-46ba-9810-02d12aa905ef",
   "metadata": {},
   "source": [
    "Selecting the value of the tuning parameter ![image.png](attachment:66a8fd8d-82d7-4afc-b2aa-82b2b2cca39d.png) in Ridge regression, also known as the regularization parameter, is a critical step in building an effective model. The choice of ![image.png](attachment:66a8fd8d-82d7-4afc-b2aa-82b2b2cca39d.png) controls the balance between fitting the data well and keeping the coefficients small to prevent overfitting. Here are some common methods for selecting the value of ![image.png](attachment:66a8fd8d-82d7-4afc-b2aa-82b2b2cca39d.png) in Ridge regression:\n",
    "\n",
    "1. **Cross-Validation**:\n",
    "   - **K-Fold Cross-Validation**: Divide the dataset into \\( k \\) subsets (folds). Train the Ridge regression model on \\( k-1 \\) folds and validate it on the remaining fold. Repeat this process \\( k \\) times, each time using a different fold as the validation set. Calculate the average performance metric (e.g., RMSE, MAE) across all folds for each value of ![image.png](attachment:66a8fd8d-82d7-4afc-b2aa-82b2b2cca39d.png). Choose the value of ![image.png](attachment:f9db8634-a41f-4077-b140-9a57d2220e7c.png) that minimizes the average error.\n",
    "   - **Leave-One-Out Cross-Validation (LOOCV)**: Similar to K-fold cross-validation, but with \\( k \\) equal to the number of observations in the dataset. This method provides a more reliable estimate of model performance but can be computationally expensive for large datasets.\n",
    "\n",
    "2. **Grid Search**:\n",
    "   - Define a range of values for ![image.png](attachment:a0134b98-4430-4edf-9001-b1c8eb551421.png) to consider (e.g., logarithmically spaced values between ![image.png](attachment:78a67d7a-2ff1-4b4a-b604-a697e7f2022f.png) and ![image.png](attachment:9bf5d4aa-885c-46b8-acdb-0b85c4ddb431.png).\n",
    "   - Train the Ridge regression model for each value of ![image.png](attachment:da6281bd-e44e-4274-8beb-e5be6d5dd086.png) in the range on the training data.\n",
    "   - Evaluate the model's performance on a validation set using a chosen performance metric.\n",
    "   - Select the value of ![image.png](attachment:24f5e5e7-01d4-44c3-a4b4-5617b11c4c66.png) that gives the best performance on the validation set.\n",
    "\n",
    "3. **Regularization Path**:\n",
    "   - Compute the regularization path, which shows how the coefficients of the predictors change as ![image.png](attachment:da41f978-a4e2-4a8a-9452-4a4cc729cc9b.png) varies.\n",
    "   - Plot the magnitude of the coefficients against the values of ![image.png](attachment:a50ec0a8-03a8-467b-987d-6571d637df67.png).\n",
    "   - Identify the value of ![image.png](attachment:43ebaabe-c524-4d91-89e9-f3afd5e2a5c1.png) where the coefficients stabilize or reach zero, indicating that some predictors are no longer contributing to the model. This approach provides insights into feature selection and model interpretability.\n",
    "\n",
    "4. **Information Criteria**:\n",
    "   - Use information criteria such as Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC) to select the optimal value of ![image.png](attachment:bdee2b2d-1acd-4fbb-bd76-1e6f7d5d2c57.png).\n",
    "   - These criteria balance model complexity (number of parameters) and goodness of fit, penalizing models with higher complexity.\n",
    "\n",
    "5. **Domain Knowledge**:\n",
    "   - Prior knowledge about the data or the problem domain can help in selecting a reasonable range for ![image.png](attachment:94281279-13d3-4739-8869-3b9109931219.png).\n",
    "   - For example, if certain predictors are expected to have a small effect on the outcome, higher values of ![image.png](attachment:22b9e86b-89f7-411a-889c-f964c329174c.png) can be considered to shrink their coefficients more aggressively.\n",
    "\n",
    "In practice, a combination of these methods, such as cross-validation with grid search or a regularized path approach, is often used to select the optimal value of \\( \\lambda \\) in Ridge regression. The choice depends on the specific characteristics of the dataset, computational resources available, and the trade-offs between model performance and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641bc0c-f6a5-4759-950f-7c98ecf53e80",
   "metadata": {},
   "source": [
    "# Answer 4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "attachments": {
    "2c6bf327-2686-41d7-bdd9-474f73260ac9.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA8AAAAXCAYAAADUUxW8AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF0SURBVDhP5ZQxSAJhGEBfCQ6Gk9AgONzSlYMQeEvmYEsSVFMtOkkRNqREW7iELRGUiwaBkzU0RBLo6BAOoSA4RLY4CEJDU9AgRP2Xf5l6OjgFveXj3t2Du5+PG1MU5YMRGZdzJP5S7NDwLfnQHPJ6CP2xd4XwTpzkdZGrfU1KY/rjyxjrm3nqmFG8AfxSG2H8zY005ScxbdP4l9vKiAEH1iRTqYlpw7UUbCsDBsQiPy5Rewerc4GQdL0MjCFB8aEFFpX5Dal6GBJD6r5GSxycOheWppvBsWONo0UVs3h1s9NDROrfGMeOIKdnUdzPKRKVVzCpaHt2ebNDfyzC5HkE7S1PLJwhk6vyIrQ6G6Q3746/Q1OJ1G6cou5uCzzq9ZSbUM/KdmI9TIvQWid7sE2mIT1ZLipNMRW0re51/Ykjh2E0S5PCSZT4nZSS0k1VrA3Y3QFW2+qLzp9kxoNvok6hrD/Wj93twzXZop4rou+ezv/7DcEnmSNexDlU55YAAAAASUVORK5CYII="
    },
    "da46b00d-f0fa-4a76-9e56-0abb1cbbe3c2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA8AAAAXCAYAAADUUxW8AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF0SURBVDhP5ZQxSAJhGEBfCQ6Gk9AgONzSlYMQeEvmYEsSVFMtOkkRNqREW7iELRGUiwaBkzU0RBLo6BAOoSA4RLY4CEJDU9AgRP2Xf5l6OjgFveXj3t2Du5+PG1MU5YMRGZdzJP5S7NDwLfnQHPJ6CP2xd4XwTpzkdZGrfU1KY/rjyxjrm3nqmFG8AfxSG2H8zY005ScxbdP4l9vKiAEH1iRTqYlpw7UUbCsDBsQiPy5Rewerc4GQdL0MjCFB8aEFFpX5Dal6GBJD6r5GSxycOheWppvBsWONo0UVs3h1s9NDROrfGMeOIKdnUdzPKRKVVzCpaHt2ebNDfyzC5HkE7S1PLJwhk6vyIrQ6G6Q3746/Q1OJ1G6cou5uCzzq9ZSbUM/KdmI9TIvQWid7sE2mIT1ZLipNMRW0re51/Ykjh2E0S5PCSZT4nZSS0k1VrA3Y3QFW2+qLzp9kxoNvok6hrD/Wj93twzXZop4rou+ezv/7DcEnmSNexDlU55YAAAAASUVORK5CYII="
    },
    "dace4cdf-9d5d-4b6b-a8d2-211d0c1a83e0.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA8AAAAXCAYAAADUUxW8AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF0SURBVDhP5ZQxSAJhGEBfCQ6Gk9AgONzSlYMQeEvmYEsSVFMtOkkRNqREW7iELRGUiwaBkzU0RBLo6BAOoSA4RLY4CEJDU9AgRP2Xf5l6OjgFveXj3t2Du5+PG1MU5YMRGZdzJP5S7NDwLfnQHPJ6CP2xd4XwTpzkdZGrfU1KY/rjyxjrm3nqmFG8AfxSG2H8zY005ScxbdP4l9vKiAEH1iRTqYlpw7UUbCsDBsQiPy5Rewerc4GQdL0MjCFB8aEFFpX5Dal6GBJD6r5GSxycOheWppvBsWONo0UVs3h1s9NDROrfGMeOIKdnUdzPKRKVVzCpaHt2ebNDfyzC5HkE7S1PLJwhk6vyIrQ6G6Q3746/Q1OJ1G6cou5uCzzq9ZSbUM/KdmI9TIvQWid7sE2mIT1ZLipNMRW0re51/Ykjh2E0S5PCSZT4nZSS0k1VrA3Y3QFW2+qLzp9kxoNvok6hrD/Wj93twzXZop4rou+ezv/7DcEnmSNexDlU55YAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "67098314-4b51-4ab4-826d-4dd7c2305f74",
   "metadata": {},
   "source": [
    "Yes, Ridge regression can be used for feature selection, although it does not perform feature selection as explicitly as Lasso regression. While Ridge regression does not set coefficients exactly to zero, it can still help identify and prioritize important features by shrinking their coefficients towards zero.\n",
    "\n",
    "Here's how Ridge regression can be used for feature selection:\n",
    "\n",
    "1. **Coefficient Magnitudes**: Ridge regression penalizes large coefficients by adding a penalty term to the loss function. As the regularization parameter ![image.png](attachment:da46b00d-f0fa-4a76-9e56-0abb1cbbe3c2.png) increases, the magnitude of the coefficients decreases. Features with smaller coefficients after regularization are considered less important or less influential in predicting the target variable.\n",
    "\n",
    "2. **Regularization Path**: By examining the regularization path, which shows how the coefficients change as ![image.png](attachment:dace4cdf-9d5d-4b6b-a8d2-211d0c1a83e0.png) varies, you can identify the relative importance of features. Plotting the magnitude of the coefficients against the values of ![image.png](attachment:2c6bf327-2686-41d7-bdd9-474f73260ac9.png) can provide insights into which features are more influential in the model.\n",
    "\n",
    "3. **Stability Selection**: This technique combines Ridge regression with resampling methods, such as bootstrapping or subsampling. Multiple Ridge regression models are trained on random subsets of the data, each time with different subsets of predictors. The stability of each feature is assessed based on how frequently it appears as important across different subsets. Features that are consistently selected across multiple models are considered more stable and are likely to be important.\n",
    "\n",
    "4. **Hybrid Approaches**: You can combine Ridge regression with other feature selection techniques, such as univariate feature selection or recursive feature elimination (RFE). For example, you can use Ridge regression as a filter method to rank features based on their coefficients and then apply another feature selection method, such as RFE, to further refine the selection.\n",
    "\n",
    "5. **Domain Knowledge**: Prior knowledge about the data or the problem domain can also guide feature selection in Ridge regression. You can incorporate domain expertise to prioritize certain features or exclude irrelevant ones from the model.\n",
    "\n",
    "While Ridge regression can help identify important features, it's essential to interpret the results carefully and consider the trade-offs between model complexity and performance. Additionally, if explicit feature selection is a primary goal, Lasso regression may be more suitable, as it tends to produce sparse solutions by setting some coefficients exactly to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a930365-20d1-4fc5-8983-d3d25ab183d6",
   "metadata": {},
   "source": [
    "# Answer 5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "attachments": {
    "277783c5-b872-4083-91a6-1793de0f6b1a.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAsAAAATCAYAAABGKffQAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAFnSURBVDhPnZM/SEJBHIA/FRwMJ6FBcHhLLxyEwLdUDrYkQjXVopMUYUNKtIVL2BJBuWgQOL0aGiIJdHQIh1AQHCJbHAShoSloEMJO35l/B+lbfrzvvuGOu2dSFKXDjJjlnIl/xi4Nf9CP5pLfUxjEvk2ih0nSDyXuTzQpRxnEdwl29go0sKL4QgSkHmZ0z80slXcxHYsENgw1zNgBW+jVupgOPMGwoYYYi0V+Uab+A3b3GhHp+kzEkKL02gabyuquVJIpMWRe6rTFQdXlqDQGk7Frm/N1FavYitW9QkzqLqOxK8zVdRzvR4ZU9QssKtqxUy4OxyJM38TQvgskojp6vsan0OpSmH5uxP3QUiZzlKTUdU9F3rr1gpeIfALmXpgVob1B7vQAvWksQI7baktMBW3fuH5z7CyKZmtRvIyTfO65P8qPNXFN4PSG2BLTpATDHf9cg2Klqydxev145ts08iURz/ynwC+tq13jLiLNjQAAAABJRU5ErkJggg=="
    },
    "46f60804-b4db-491e-91e3-a055cefae6ae.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAsAAAATCAYAAABGKffQAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAFnSURBVDhPnZM/SEJBHIA/FRwMJ6FBcHhLLxyEwLdUDrYkQjXVopMUYUNKtIVL2BJBuWgQOL0aGiIJdHQIh1AQHCJbHAShoSloEMJO35l/B+lbfrzvvuGOu2dSFKXDjJjlnIl/xi4Nf9CP5pLfUxjEvk2ih0nSDyXuTzQpRxnEdwl29go0sKL4QgSkHmZ0z80slXcxHYsENgw1zNgBW+jVupgOPMGwoYYYi0V+Uab+A3b3GhHp+kzEkKL02gabyuquVJIpMWRe6rTFQdXlqDQGk7Frm/N1FavYitW9QkzqLqOxK8zVdRzvR4ZU9QssKtqxUy4OxyJM38TQvgskojp6vsan0OpSmH5uxP3QUiZzlKTUdU9F3rr1gpeIfALmXpgVob1B7vQAvWksQI7baktMBW3fuH5z7CyKZmtRvIyTfO65P8qPNXFN4PSG2BLTpATDHf9cg2Klqydxev145ts08iURz/ynwC+tq13jLiLNjQAAAABJRU5ErkJggg=="
    },
    "dced13c5-d9f2-4933-bf29-63d402071833.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAsAAAATCAYAAABGKffQAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAFnSURBVDhPnZM/SEJBHIA/FRwMJ6FBcHhLLxyEwLdUDrYkQjXVopMUYUNKtIVL2BJBuWgQOL0aGiIJdHQIh1AQHCJbHAShoSloEMJO35l/B+lbfrzvvuGOu2dSFKXDjJjlnIl/xi4Nf9CP5pLfUxjEvk2ih0nSDyXuTzQpRxnEdwl29go0sKL4QgSkHmZ0z80slXcxHYsENgw1zNgBW+jVupgOPMGwoYYYi0V+Uab+A3b3GhHp+kzEkKL02gabyuquVJIpMWRe6rTFQdXlqDQGk7Frm/N1FavYitW9QkzqLqOxK8zVdRzvR4ZU9QssKtqxUy4OxyJM38TQvgskojp6vsan0OpSmH5uxP3QUiZzlKTUdU9F3rr1gpeIfALmXpgVob1B7vQAvWksQI7baktMBW3fuH5z7CyKZmtRvIyTfO65P8qPNXFN4PSG2BLTpATDHf9cg2Klqydxev145ts08iURz/ynwC+tq13jLiLNjQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "3b1ade7d-5c86-4948-aa89-aebc35b91e4e",
   "metadata": {},
   "source": [
    "Ridge regression is particularly well-suited for handling multicollinearity, which occurs when two or more predictor variables are highly correlated with each other. Multicollinearity can lead to unstable coefficient estimates in ordinary least squares (OLS) regression, making the interpretation of the model challenging and potentially inflating the variance of the coefficient estimates.\n",
    "\n",
    "Here's how Ridge regression performs in the presence of multicollinearity:\n",
    "\n",
    "1. **Shrinkage of Coefficients**: Ridge regression adds a penalty term to the OLS loss function, which is proportional to the squared sum of the coefficients. As a result, Ridge regression shrinks the coefficients towards zero, reducing their variance. This shrinkage helps stabilize the coefficient estimates, even when multicollinearity is present.\n",
    "\n",
    "2. **Bias-Variance Trade-off**: By introducing a bias into the coefficient estimates through the regularization term, Ridge regression achieves a balance between bias and variance. While the bias increases as the coefficients are shrunk towards zero, the variance of the estimates decreases, resulting in more stable predictions overall. This trade-off can lead to improved generalization performance, especially when multicollinearity is a concern.\n",
    "\n",
    "3. **Equal Treatment of Correlated Predictors**: Unlike OLS regression, which can produce highly variable coefficient estimates when predictors are highly correlated, Ridge regression treats correlated predictors equally. By penalizing large coefficients, Ridge regression effectively mitigates the impact of multicollinearity on the coefficient estimates and reduces their sensitivity to small changes in the data.\n",
    "\n",
    "4. **Regularization Parameter**: The effectiveness of Ridge regression in handling multicollinearity depends on the choice of the regularization parameter ![image.png](attachment:dced13c5-d9f2-4933-bf29-63d402071833.png). A larger ![image.png](attachment:277783c5-b872-4083-91a6-1793de0f6b1a.png) value leads to stronger regularization, which can shrink the coefficients more aggressively and reduce the impact of multicollinearity. However, excessively large values of ![image.png](attachment:46f60804-b4db-491e-91e3-a055cefae6ae.png) may bias the coefficient estimates too much, leading to underfitting.\n",
    "\n",
    "In summary, Ridge regression is well-suited for handling multicollinearity by stabilizing coefficient estimates through shrinkage towards zero. It achieves a balance between bias and variance, leading to more robust predictions, especially in situations where multicollinearity is present. However, it's essential to select an appropriate value for the regularization parameter to achieve the desired level of regularization without overly biasing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c4d72d-fd8b-4e6c-82aa-80ff5911793f",
   "metadata": {},
   "source": [
    "# Answer 6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da99986f-aae1-4b38-8d59-b9c81a337ea9",
   "metadata": {},
   "source": [
    "Yes, Ridge regression can handle both categorical and continuous independent variables. However, categorical variables need to be appropriately encoded before being used in the regression model.\n",
    "\n",
    "Here's how Ridge regression can handle different types of independent variables:\n",
    "\n",
    "1. **Continuous Variables**: Ridge regression directly accepts continuous independent variables in their original numeric form. These variables are used as-is in the regression model, and Ridge regression estimates coefficients for each continuous predictor variable.\n",
    "\n",
    "2. **Categorical Variables**: Categorical variables need to be converted into a suitable numeric format before being used in Ridge regression. This process is called encoding. There are several methods for encoding categorical variables:\n",
    "\n",
    "   - **Dummy Coding**: In dummy coding, each categorical variable with \\( k \\) levels is replaced by \\( k-1 \\) binary (0/1) dummy variables. One level is chosen as the reference category, and the remaining levels are represented by the dummy variables. Ridge regression then estimates a separate coefficient for each dummy variable.\n",
    "   \n",
    "   - **One-Hot Encoding**: One-hot encoding is a variation of dummy coding where each categorical variable with \\( k \\) levels is replaced by \\( k \\) binary dummy variables. Each dummy variable represents a single level of the categorical variable, and Ridge regression estimates a separate coefficient for each dummy variable.\n",
    "   \n",
    "   - **Ordinal Encoding**: In ordinal encoding, each level of a categorical variable is assigned a unique integer value. Ridge regression then treats the ordinal variable as a continuous variable and estimates a single coefficient for it. This approach assumes an ordered relationship between the levels of the categorical variable.\n",
    "\n",
    "3. **Interaction Terms**: Ridge regression can also handle interaction terms between continuous and categorical variables. Interaction terms capture the combined effect of two or more variables on the outcome. For example, an interaction term between a continuous variable (e.g., age) and a categorical variable (e.g., gender) allows the effect of age on the outcome to vary by gender.\n",
    "\n",
    "In summary, Ridge regression can handle both categorical and continuous independent variables, but categorical variables need to be appropriately encoded before being used in the regression model. Ridge regression estimates coefficients for each independent variable, including both continuous and encoded categorical variables, to model their relationship with the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580627fd-768d-4b6d-80b9-546157a71a5c",
   "metadata": {},
   "source": [
    "# Answer 7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "attachments": {
    "c4b7829c-d870-4227-9bd9-7298baa76d3d.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA8AAAAYCAYAAAAlBadpAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF5SURBVDhP7ZQ/SAJRHMe/JdRSk9uFw6NBG7QEpUFuMIKOomypIVuClnMxIqQhh6QhXHJzkaYrqCaXUAiclOK2i/7cFgg2OUUNQtS7ey//dHdBTg19lt973/c+/Pi94Q0QQj7QJ4O89sVfkicikOYj8PLtT1jksBSHvJODcl1Cbo2HDlhk9SiBWEHFi8uNyEKSp/bYz3xahtakdTyMlIdFdjg8WBEVndouL0IbAs+sOMhULz/CaE6mZIRZZMFRxuUJtGdaPQEsTbPoO84yVFzcNWgVEFi27+0si0nIQTavEIxDMle92MtiCsr+KkZqaRSf6N7tg7TIjrqxyuIezg9XIOh5bGVKOL7RaeiGbzbGzrvolU0xhrFGEWlZgTFx40yD/k51/xzW2a02HZmL5E1FfvsAVR6jnkX1vgWMTmJmk2ccLkeR3TXEWyiZBJQ6S7/I13S0MAR/NEXfvkP7JxFCUZDXCqoPZm7BK0ogw01oV6o5jsH/N/QrgE8hHl/MZh2BOwAAAABJRU5ErkJggg=="
    },
    "f0861037-193d-4347-acfb-f94fd0aba751.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA8AAAAYCAYAAAAlBadpAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF5SURBVDhP7ZQ/SAJRHMe/JdRSk9uFw6NBG7QEpUFuMIKOomypIVuClnMxIqQhh6QhXHJzkaYrqCaXUAiclOK2i/7cFgg2OUUNQtS7ey//dHdBTg19lt973/c+/Pi94Q0QQj7QJ4O89sVfkicikOYj8PLtT1jksBSHvJODcl1Cbo2HDlhk9SiBWEHFi8uNyEKSp/bYz3xahtakdTyMlIdFdjg8WBEVndouL0IbAs+sOMhULz/CaE6mZIRZZMFRxuUJtGdaPQEsTbPoO84yVFzcNWgVEFi27+0si0nIQTavEIxDMle92MtiCsr+KkZqaRSf6N7tg7TIjrqxyuIezg9XIOh5bGVKOL7RaeiGbzbGzrvolU0xhrFGEWlZgTFx40yD/k51/xzW2a02HZmL5E1FfvsAVR6jnkX1vgWMTmJmk2ccLkeR3TXEWyiZBJQ6S7/I13S0MAR/NEXfvkP7JxFCUZDXCqoPZm7BK0ogw01oV6o5jsH/N/QrgE8hHl/MZh2BOwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "f7b2c2b7-41b8-4d27-b4dd-765127656ac5",
   "metadata": {},
   "source": [
    "The interpretation of coefficients in Ridge regression is similar to that in ordinary least squares (OLS) regression, with some important differences due to the regularization term added to the loss function. Here's how to interpret the coefficients of Ridge regression:\n",
    "\n",
    "1. **Magnitude of Coefficients**:\n",
    "   - In Ridge regression, the coefficients represent the change in the dependent variable (outcome) associated with a one-unit change in the corresponding predictor variable, holding all other variables constant.\n",
    "   - The magnitude of the coefficients indicates the strength of the relationship between each predictor variable and the outcome. Larger coefficients suggest a stronger impact on the outcome, while smaller coefficients suggest a weaker impact.\n",
    "\n",
    "2. **Shrinkage Towards Zero**:\n",
    "   - Due to the regularization term added to the loss function, Ridge regression shrinks the coefficients towards zero to prevent overfitting. As a result, the coefficients are typically smaller than those estimated by OLS regression.\n",
    "   - The degree of shrinkage depends on the value of the regularization parameter ![image.png](attachment:c4b7829c-d870-4227-9bd9-7298baa76d3d.png). Larger values of ![image.png](attachment:f0861037-193d-4347-acfb-f94fd0aba751.png) lead to more aggressive shrinkage, resulting in smaller coefficient estimates.\n",
    "\n",
    "3. **Relative Importance**:\n",
    "   - While Ridge regression does not set coefficients exactly to zero (except in extreme cases), it can still help identify important predictors by prioritizing those with larger coefficient magnitudes.\n",
    "   - The relative importance of predictors can be assessed by comparing the magnitudes of the coefficients. Predictors with larger coefficients are generally considered more influential in predicting the outcome.\n",
    "\n",
    "4. **Interactions and Nonlinear Effects**:\n",
    "   - The interpretation of coefficients in Ridge regression assumes a linear relationship between predictors and the outcome. However, Ridge regression can still capture interactions and nonlinear effects, as long as they are represented by the predictor variables included in the model.\n",
    "   - Interaction terms or polynomial terms can be included in the model to capture nonlinear relationships, and the coefficients associated with these terms can be interpreted similarly to coefficients of linear terms.\n",
    "\n",
    "5. **Standardization**:\n",
    "   - To facilitate the comparison of coefficients across predictors, it's common practice to standardize the predictor variables (e.g., by subtracting the mean and dividing by the standard deviation) before fitting the Ridge regression model. This ensures that all predictors are on the same scale, and the coefficients represent the change in the outcome per standard deviation change in the predictor.\n",
    "\n",
    "In summary, while the interpretation of coefficients in Ridge regression is similar to that in OLS regression, Ridge regression shrinks the coefficients towards zero to prevent overfitting. The interpretation involves assessing the magnitude of coefficients, considering the degree of shrinkage, and comparing the relative importance of predictors in predicting the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1e873-4bdf-4c6f-8027-38767fd1b0a5",
   "metadata": {},
   "source": [
    "# Answer 8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "attachments": {
    "579d1577-5e13-484e-8188-b94b199ec5ee.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAXCAYAAAAC9s/ZAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF8SURBVDhP3ZQ9SMNAGIZfLeiiU7dIh8OhdWi10OJQMkQEg6J10cG6CC7pUhEpDnawOEgXu3UpTlFQpyzSgtCpRckW8SebUKhTJ9GhIHrpHdqfJINO+ixf7r18D/cDN0AI+cAvGOT1x/xbwUQM8nwMfj50w1YQlRNQdvJQr0vIr/HQAVuBfpREvKjjxeNFbCHFU3ucz+C0DKNJ63gUaR+L7HA5RA0Vkxo8fkQ2BJ714yKgivIjrEWQKQVRFvXhKsDlCYxnWn0hLE2zqBd3AXRc3DVoFRBatl+Du0BMQQmz/QvhBOT2VzfOAjENdX8VI7UMtCc69gYgL7KpTuwF4h7OD1cgmAVsZUs4vjFp6EVgNs7mO+gXtJvjGGtoyCgqrBNonBkw36kiOId19tcX3QLeTN50FLYPUOUx6jlU71vA6CRmNnnG6RBIyO1azbdQs0modR5zCjUTLQwhKKXpnXzT9aQJEQnktYLqAw968IsyyHATxpXe3prFn38TgU9O0V/K6TSnuAAAAABJRU5ErkJggg=="
    },
    "bef34e25-fec4-450d-8941-fb64cc81a48e.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAXCAYAAAAC9s/ZAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF8SURBVDhP3ZQ9SMNAGIZfLeiiU7dIh8OhdWi10OJQMkQEg6J10cG6CC7pUhEpDnawOEgXu3UpTlFQpyzSgtCpRckW8SebUKhTJ9GhIHrpHdqfJINO+ixf7r18D/cDN0AI+cAvGOT1x/xbwUQM8nwMfj50w1YQlRNQdvJQr0vIr/HQAVuBfpREvKjjxeNFbCHFU3ucz+C0DKNJ63gUaR+L7HA5RA0Vkxo8fkQ2BJ714yKgivIjrEWQKQVRFvXhKsDlCYxnWn0hLE2zqBd3AXRc3DVoFRBatl+Du0BMQQmz/QvhBOT2VzfOAjENdX8VI7UMtCc69gYgL7KpTuwF4h7OD1cgmAVsZUs4vjFp6EVgNs7mO+gXtJvjGGtoyCgqrBNonBkw36kiOId19tcX3QLeTN50FLYPUOUx6jlU71vA6CRmNnnG6RBIyO1azbdQs0modR5zCjUTLQwhKKXpnXzT9aQJEQnktYLqAw968IsyyHATxpXe3prFn38TgU9O0V/K6TSnuAAAAABJRU5ErkJggg=="
    },
    "dee10b00-235d-4f52-9503-fe031acf2b5d.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAAXCAYAAAD+4+QTAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAKZSURBVEhL7ZVPSJNhHMc/Zby3nZTCieEMHAXTIF+KXiySDkPI0WF2WRCvh5BECcwObnXwkjMoO/giyYJ489Au1aUFMYh4u2yHYhANKqVwnQbCQvAFqef9o66ca8K89YHxe37f53n3fd/n93ufd5/P5/vFHrPfjXtKHU38KFfGmRxTUY66kkt9TFojzL6IM+j3QFuI+CODp7cUd7JOJvLVMF3SMh+exYgNh9A/gq9viFF3vj5Psg5SYzstjU6qLS1Dgxf/JSev3F1jCYyLASTJzS1ME7NBQmoQw5UC+Xc6U7eT5N3pcoYSBuqRPNpZlYTIKz/JXVE8Reb5Fysxyc3LyIqCckpEOcL99xDoG0fTInjtC8roiRM8tkZuQbMNLKpsl/iDg1Zc5uucLbjkSd7IsChGnu5+VEd0sBpgopPiQgx1LuOK1Uz6umkXzcKPJV45yhaXvTRZcd2kZAuC1jDx6X5+zquoDwyCE5OMHnemdjTxdnux6lj8nGbrnhzUM11Y/qVsihlbUYjeCSO9fkJ6tZPwtSgDJ3wgttXigBO2E/aLRaIehXzKESxaZSIjUQYDUMjqxId1Ww5Oxwh1iFvqiAo7l5UML93hDmeX2Nv0KLJHbEexJKwEkodGj4S5lEKb0tCzBXtlLVTers16GNwMBglav94wM9kSUlsvwR5nWa1UNNmoR+lbpqweBfS3n0ShJfwn/+ipf1LRZKMeS7mkI7jIgRa74OZq0RFqpIJJBH+zFf9+P+D0YefVW1vbbNya2G5yYaf3I0CTpZehPkyjX3eTKmyZjCRIvzHIiCPaPueazzFrWEe26FebHKnsot1pnpZOxid0Bg5lSd5zZqux68+vv0cldN6HxyxgPNZIfXcnqvD/G78L4De6ucSuYboYSQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "62bb8ccb-3b9d-48a0-bc78-775593573f0e",
   "metadata": {},
   "source": [
    "Yes, Ridge regression can be used for time-series data analysis, particularly when there are concerns about multicollinearity or overfitting in the regression model. While Ridge regression is commonly applied to cross-sectional data, it can also be adapted for time-series analysis with some modifications.\n",
    "\n",
    "Here's how Ridge regression can be used for time-series data analysis:\n",
    "\n",
    "1. **Feature Engineering**: Time-series data often involves temporal patterns and trends. Before applying Ridge regression, it's essential to engineer appropriate features from the time-series data. This may include lagged variables, moving averages, seasonality indicators, or other transformations to capture relevant temporal patterns.\n",
    "\n",
    "2. **Multicollinearity Handling**: Time-series data often exhibit multicollinearity, where predictor variables are highly correlated with each other due to their temporal nature. Ridge regression can handle multicollinearity by penalizing large coefficients, reducing their variance, and stabilizing the coefficient estimates.\n",
    "\n",
    "3. **Regularization Parameter Selection**: The choice of the regularization parameter ![image.png](attachment:579d1577-5e13-484e-8188-b94b199ec5ee.png) in Ridge regression is critical for controlling the trade-off between fitting the data well and keeping the coefficients small. Cross-validation techniques, such as time-series cross-validation (e.g., rolling-window or expanding-window cross-validation), can be used to select an optimal value of ![image.png](attachment:bef34e25-fec4-450d-8941-fb64cc81a48e.png) that balances model complexity and performance.\n",
    "\n",
    "4. **Model Evaluation**: After fitting the Ridge regression model to the time-series data, it's essential to evaluate its performance using appropriate metrics. Common evaluation metrics for time-series regression models include mean squared error (MSE), mean absolute error (MAE), root mean squared error (RMSE), and ![image.png](attachment:dee10b00-235d-4f52-9503-fe031acf2b5d.png) coefficient of determination. It's also important to assess the model's ability to capture temporal patterns, trends, and seasonality in the data.\n",
    "\n",
    "5. **Interpretation**: Interpretation of the coefficients in Ridge regression for time-series data follows similar principles as in cross-sectional data analysis. However, it's important to consider the temporal nature of the predictors and the potential lagged effects when interpreting the coefficients.\n",
    "\n",
    "6. **Model Extensions**: Depending on the specific characteristics of the time-series data, extensions of Ridge regression may be considered. For example, autoregressive integrated moving average (ARIMA) models or autoregressive distributed lag (ARDL) models combine autoregressive and lagged terms with Ridge regression to capture temporal dependencies more explicitly.\n",
    "\n",
    "In summary, while Ridge regression is primarily used for cross-sectional data analysis, it can be adapted for time-series data analysis by incorporating appropriate feature engineering, handling multicollinearity, selecting an optimal regularization parameter, evaluating model performance, and interpreting the results in the context of temporal patterns and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32a9e9-e5ed-4a36-94cc-c746de85f25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
