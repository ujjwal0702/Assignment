{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af252bd-0a8f-4d18-8b33-f102a6dc2b4c",
   "metadata": {},
   "source": [
    "# Answer 1:\n",
    "Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71dccb-f222-4fea-82e1-cdff0a7e9a7b",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare the means of three or more groups to determine if there are statistically significant differences between them. However, ANOVA relies on several key assumptions, and violations of these assumptions can impact the validity of the results. Here are the primary assumptions for using ANOVA and examples of violations:\n",
    "\n",
    "1. Independence of Observations:\n",
    "   - Assumption: Observations within and between groups are independent of each other. This means that the data points in one group should not be related to the data points in another group.\n",
    "   - Violation Example: If data points within groups are not independent, such as repeated measures on the same subjects, this assumption is violated. For instance, a repeated-measures ANOVA for assessing the effect of a drug on a group of patients would violate this assumption.\n",
    "\n",
    "2. Normality of Residuals:\n",
    "   - Assumption: The residuals (the differences between the observed values and the group means) are normally distributed. In other words, the data within each group should follow a normal distribution.\n",
    "   - Violation Example: If the residuals are not normally distributed, it can lead to inaccurate p-values and confidence intervals. For instance, if the residuals have a skewed or non-normal distribution, ANOVA results may be unreliable.\n",
    "\n",
    "3. Homogeneity of Variances (Homoscedasticity):\n",
    "   - Assumption: The variances of the residuals should be approximately equal across all groups, meaning that the spread of data points should be roughly the same.\n",
    "   - Violation Example: If the variances are not equal, it can lead to unequal variances across groups and can affect the F-statistic and p-values. For example, one group may have much larger variances than the others, indicating a violation of this assumption.\n",
    "\n",
    "4. Independence of Errors:\n",
    "   - Assumption: Errors (residuals) should be uncorrelated with each other. There should be no systematic patterns in the residuals.\n",
    "   - Violation Example: If there is a systematic pattern or correlation in the residuals, it may indicate a violation of this assumption. For instance, if the residuals show a clear trend or pattern over time or some other variable, this assumption is violated.\n",
    "\n",
    "5. Equal Group Sizes (for one-way ANOVA):\n",
    "   - Assumption: In one-way ANOVA, the groups should have roughly equal sample sizes.\n",
    "   - Violation Example: If the sample sizes are significantly different between groups, it can impact the validity of ANOVA results. For example, if one group has many more observations than the others, it can disproportionately influence the results.\n",
    "\n",
    "Violations of these assumptions can lead to inaccurate p-values, inflated Type I error rates, and unreliable conclusions. In such cases, it might be necessary to consider alternative statistical methods or transformations of the data to address the violations. When violations are severe, non-parametric tests or robust ANOVA procedures may be more appropriate. Additionally, checking for and addressing these assumptions should be a critical step in the data analysis process when using ANOVA to ensure the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90daf328-b881-4e3f-9fe6-5d8fba61e14b",
   "metadata": {},
   "source": [
    "# Answer 2: \n",
    "What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe8cf96-5f82-4d61-839f-c2b2ffab01f6",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare the means of multiple groups to determine if there are statistically significant differences between them. There are three main types of ANOVA, each suited for different situations:\n",
    "\n",
    "1. One-Way ANOVA:\n",
    "   - Situation: One-way ANOVA is used when you have one independent variable (categorical) with more than two levels or groups, and you want to determine if there are any statistically significant differences in the means of the dependent variable between these groups.\n",
    "   - Example: You want to compare the average test scores of students from different classes (Class A, Class B, and Class C) to see if there is a statistically significant difference in performance among the classes.\n",
    "\n",
    "2. Two-Way ANOVA:\n",
    "   - Situation: Two-way ANOVA is used when you have two independent variables, and you want to analyze the effects of both variables on the dependent variable. It allows you to determine if there are main effects for each independent variable and whether there is an interaction effect between them.\n",
    "   - Example: You want to study the effects of both gender (male and female) and treatment type (A and B) on the test scores of students. Two-way ANOVA can help you determine if gender, treatment, or their interaction significantly affect the test scores.\n",
    "\n",
    "3. N-Way ANOVA (Multifactorial ANOVA):\n",
    "   - Situation: N-way ANOVA is an extension of two-way ANOVA and is used when you have more than two independent variables. It allows you to examine the effects of multiple factors on a dependent variable.\n",
    "   - Example: You are conducting a research study on plant growth and want to analyze the effects of factors such as the type of fertilizer (A, B, or C), the amount of sunlight (low, medium, high), and the soil type (clay, loam, sandy) on plant height. N-way ANOVA can be used to determine the combined effects of all these factors on plant growth.\n",
    "\n",
    "It's essential to choose the appropriate type of ANOVA based on the nature of your research design and the number of independent variables you are working with. One-way ANOVA is suitable for single-factor designs, while two-way and N-way ANOVA are used in multifactorial designs where you want to investigate the interactions between multiple independent variables. The choice of ANOVA also depends on the research question and the specific hypotheses you aim to test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83875674-3bff-4728-bfee-b1640bdf016f",
   "metadata": {},
   "source": [
    "# Answer 3: \n",
    "What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460a23b-93fb-4bd9-af69-799135ba07d2",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA (Analysis of Variance) is the process of decomposing the total variance observed in a dataset into different components that represent the sources of variation in the data. This concept is crucial for understanding the relative contributions of various factors and for assessing the significance of these factors in explaining the observed differences in group means. In ANOVA, the variance is partitioned into three main components:\n",
    "\n",
    "1. Total Variance (Total Sum of Squares, SST):\n",
    "   - SST represents the total variability in the data. It quantifies the sum of the squared differences between each data point and the overall mean of all the data points. SST captures the total spread or variability in the dataset.\n",
    "\n",
    "2. Between-Group Variance (Between-Groups Sum of Squares, SSB):\n",
    "   - SSB measures the variance that results from differences between the group means. It quantifies the extent to which the group means differ from each other. In ANOVA, the goal is to determine if this between-group variance is statistically significant, indicating that the groups or treatments have different effects.\n",
    "\n",
    "3. Within-Group Variance (Within-Groups Sum of Squares, SSW or SSE):\n",
    "   - SSW represents the variance within each group or treatment. It measures the variation or spread of data points within individual groups. Smaller SSW relative to SST suggests that most of the variance is due to differences between groups, making it more likely that the group means are different from each other.\n",
    "\n",
    "The formula for partitioning the total variance is typically expressed as follows:\n",
    "\n",
    "SST = SSB + SSW (or SSE)\n",
    "\n",
    "Understanding this partitioning is essential for several reasons:\n",
    "\n",
    "1. **Hypothesis Testing**: ANOVA is designed to test whether the differences between group means are statistically significant. By partitioning the variance, ANOVA helps determine whether the observed between-group variance is larger than what would be expected by random chance.\n",
    "\n",
    "2. **Interpretation**: It provides a clear breakdown of the sources of variation, helping researchers understand where the differences in group means originate. This is valuable for identifying which groups or treatments are contributing most to the overall variability.\n",
    "\n",
    "3. **Model Selection**: Variance partitioning helps researchers choose the appropriate statistical model for their data. It can reveal whether a one-way, two-way, or N-way ANOVA is the most appropriate for the research question.\n",
    "\n",
    "4. **Effect Size**: Understanding the partitioning of variance can provide insights into the size of the effect. If the between-group variance is relatively large compared to the within-group variance, it suggests a stronger effect.\n",
    "\n",
    "5. **Assumptions and Model Checking**: Researchers can use the partitioning of variance to check the assumptions of ANOVA, such as homogeneity of variances and normality of residuals, which can impact the validity of the results.\n",
    "\n",
    "By breaking down the total variance into these components, ANOVA helps researchers make valid conclusions about whether the observed differences between groups are statistically significant and whether these differences are practically meaningful in the context of their research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae20ed2-5517-43a4-930a-5b4dfa0042cb",
   "metadata": {},
   "source": [
    "# Answer 4: \n",
    "How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bdf225-881f-446e-8294-3b99d9235220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST (Total Sum of Squares): 808.0\n",
      "SSE (Explained Sum of Squares): 137.2\n",
      "SSR (Residual Sum of Squares): 670.8\n",
      "F-statistic: 1.2271914132379247\n",
      "p-value: 0.3274086574259102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for three groups\n",
    "group_a = np.array([65, 68, 72, 74, 73])\n",
    "group_b = np.array([58, 60, 63, 59, 61])\n",
    "group_c = np.array([70, 75, 78, 80, 79])\n",
    "\n",
    "# Combine all data into one array\n",
    "data = np.concatenate([group_a, group_b, group_c])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate SST (Total Sum of Squares)\n",
    "sst = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "# Calculate group means\n",
    "mean_a = np.mean(group_a)\n",
    "mean_b = np.mean(group_b)\n",
    "mean_c = np.mean(group_c)\n",
    "\n",
    "# Calculate SSE (Explained Sum of Squares)\n",
    "sse = np.sum((group_a - mean_a) ** 2) + np.sum((group_b - mean_b) ** 2) + np.sum((group_c - mean_c) ** 2)\n",
    "\n",
    "# Calculate SSR (Residual Sum of Squares)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Degrees of freedom for ANOVA\n",
    "df_between = 2  # Number of groups minus 1\n",
    "df_within = len(data) - 3  # Total number of observations minus the number of groups\n",
    "\n",
    "# Calculate mean squares\n",
    "ms_between = sse / df_between\n",
    "ms_within = ssr / df_within\n",
    "\n",
    "# Calculate F-statistic\n",
    "f_statistic = ms_between / ms_within\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = 1 - stats.f.cdf(f_statistic, df_between, df_within)\n",
    "\n",
    "# Print the results\n",
    "print(\"SST (Total Sum of Squares):\", sst)\n",
    "print(\"SSE (Explained Sum of Squares):\", sse)\n",
    "print(\"SSR (Residual Sum of Squares):\", ssr)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d265a-53e2-4c7e-967e-8809ce2f6b3c",
   "metadata": {},
   "source": [
    "# Answer 5: \n",
    "In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0b6aa7-6949-4194-b613-9681d22d1bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor A: 0.5480320595019474\n",
      "Main Effect of Factor B: 0.5235909984099318\n",
      "Interaction Effect: 0.9184847345060907\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = np.array([70, 75, 80, 82, 68, 72, 78, 81, 60, 63, 65, 59, 61, 67, 71, 75, 80, 84])\n",
    "factor_a = np.array([\"A1\", \"A1\", \"A1\", \"A1\", \"A2\", \"A2\", \"A2\", \"A2\", \"A3\", \"A3\", \"A3\", \"A3\", \"A1\", \"A1\", \"A2\", \"A2\", \"A3\", \"A3\"])\n",
    "factor_b = np.array([\"B1\", \"B2\", \"B1\", \"B2\", \"B1\", \"B2\", \"B1\", \"B2\", \"B1\", \"B2\", \"B1\", \"B2\", \"B1\", \"B2\", \"B1\", \"B2\", \"B1\", \"B2\"])\n",
    "\n",
    "# Create a DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Data': data, 'FactorA': factor_a, 'FactorB': factor_b})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Data ~ C(FactorA) * C(FactorB)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effects\n",
    "main_effect_a = anova_table['PR(>F)']['C(FactorA)']\n",
    "main_effect_b = anova_table['PR(>F)']['C(FactorB)']\n",
    "interaction_effect = anova_table['PR(>F)']['C(FactorA):C(FactorB)']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor A:\", main_effect_a)\n",
    "print(\"Main Effect of Factor B:\", main_effect_b)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1f108-0953-41b6-8a6e-2174d1b80a35",
   "metadata": {},
   "source": [
    "# Answer 6: \n",
    "Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76d40c-47d2-4e45-ad96-373a1ae75ad2",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are statistically significant differences in the means of two or more groups. The p-value associated with the F-statistic indicates the probability of obtaining the observed F-statistic (or a more extreme one) if there were no true differences between the groups. \n",
    "\n",
    "In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02. To interpret these results:\n",
    "\n",
    "1. **Statistical Significance**:\n",
    "   - The p-value (0.02) is less than the commonly chosen significance level of 0.05. This indicates that the results are statistically significant, meaning that it is unlikely that you observed these differences between the groups by random chance alone.\n",
    "\n",
    "2. **Conclusions**:\n",
    "   - Since the results are statistically significant, you can conclude that there are statistically significant differences in the means of the groups being compared. In other words, at least one group is different from the others in terms of the variable you tested in your one-way ANOVA.\n",
    "\n",
    "3. **Further Analysis**:\n",
    "   - To determine which specific groups differ from each other, you may need to perform post hoc tests (e.g., Tukey's HSD, Bonferroni, or pairwise t-tests) or conduct additional exploratory analysis to identify the groups that are significantly different from one another. The one-way ANOVA itself does not tell you which specific group(s) differ; it only confirms the presence of some significant differences.\n",
    "\n",
    "4. **Effect Size**:\n",
    "   - While statistical significance is essential, you should also consider the effect size to assess the practical significance of the differences. An effect size measures the magnitude of the differences. In ANOVA, you can calculate effect sizes like eta-squared (η²) or partial eta-squared (partial η²) to quantify the proportion of variance explained by the group differences.\n",
    "\n",
    "In summary, your results indicate that there are statistically significant differences between the groups you compared in the one-way ANOVA. To understand the practical significance and which specific groups differ, you may need to perform additional analyses or post hoc tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e279d-ce36-4da7-9e63-5706627b721c",
   "metadata": {},
   "source": [
    "# Answer 7:\n",
    "In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5f20c-058a-4ad8-a15a-52c3682efdf4",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA (Analysis of Variance) is crucial because missing data can potentially bias the results and affect the validity of your analysis. There are several methods to deal with missing data in repeated measures ANOVA, each with its own potential consequences. The choice of method should be guided by the nature of the data and the reasons for missingness. Here are common methods and their potential consequences:\n",
    "\n",
    "1. **Listwise Deletion (Complete Case Analysis)**:\n",
    "   - Method: Exclude cases with missing data for any variable, essentially using only complete cases for analysis.\n",
    "   - Consequences: \n",
    "     - Pros: Simple and straightforward.\n",
    "     - Cons: Reduces the sample size, potentially leading to a loss of statistical power. May introduce selection bias if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "2. **Pairwise Deletion**:\n",
    "   - Method: Analyze each variable for each case using all available data, without excluding cases with missing data for any variable.\n",
    "   - Consequences: \n",
    "     - Pros: Retains all available data and maximizes the sample size for each variable.\n",
    "     - Cons: May introduce bias if missing data are not MCAR. Results can be difficult to interpret because sample sizes vary for different comparisons.\n",
    "\n",
    "3. **Mean Imputation**:\n",
    "   - Method: Replace missing values with the mean value of the available data for that variable.\n",
    "   - Consequences: \n",
    "     - Pros: Preserves the sample size, easy to implement.\n",
    "     - Cons: Alters the distribution of the variable, potentially reducing the variance, leading to underestimation of standard errors, and potentially introducing bias if data are not MCAR. It also fails to account for the variability in the missing data.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF)**:\n",
    "   - Method: Replace missing values with the last observed value for the same subject in the time series.\n",
    "   - Consequences: \n",
    "     - Pros: Preserves the time structure and may be appropriate for some clinical or longitudinal data.\n",
    "     - Cons: Assumes that the last observed value is a valid representation of the missing value, which may not be the case. It can lead to inaccurate results, especially if data are not missing completely at random.\n",
    "\n",
    "5. **Multiple Imputation**:\n",
    "   - Method: Generate multiple datasets with imputed values to account for the uncertainty related to missing data.\n",
    "   - Consequences: \n",
    "     - Pros: Preserves the sample size and accounts for variability in imputed values. Provides more accurate and unbiased estimates when missing data are not MCAR.\n",
    "     - Cons: Requires advanced statistical software and may be computationally intensive. Results should be combined from multiple imputed datasets.\n",
    "\n",
    "6. **Model-Based Imputation**:\n",
    "   - Method: Impute missing values using a model that considers the relationship between variables and the pattern of missingness.\n",
    "   - Consequences: \n",
    "     - Pros: Can provide accurate imputations when the missing data pattern has a structure. Preserves sample size.\n",
    "     - Cons: Requires the formulation of an appropriate imputation model, which can be complex.\n",
    "\n",
    "The choice of how to handle missing data in a repeated measures ANOVA should be guided by the specific context and the reasons for missingness. It is generally advisable to use multiple imputation or other methods that account for the uncertainty introduced by missing data when data are not missing completely at random. Whatever method you choose, it's important to report your handling of missing data and discuss potential limitations and biases associated with your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b555e78-d509-4465-923f-a03be7dc142f",
   "metadata": {},
   "source": [
    "# Answer 8:\n",
    "What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738cb433-9e40-4d18-8218-211885e4fe90",
   "metadata": {},
   "source": [
    "After conducting an analysis of variance (ANOVA) and finding statistically significant differences among groups, post-hoc tests are often used to identify which specific group(s) differ from each other. Commonly used post-hoc tests include:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD)**:\n",
    "   - When to Use: Tukey's HSD is widely used when you have conducted a one-way ANOVA and you want to perform multiple pairwise comparisons to identify which specific groups are different.\n",
    "   - Example: In a study comparing the effects of four different treatments on pain relief, an ANOVA indicates that there is a significant difference. Tukey's HSD can be used to determine which treatments are significantly different from each other.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - When to Use: Bonferroni correction is suitable when conducting multiple pairwise comparisons following ANOVA. It controls the familywise error rate by adjusting the significance level.\n",
    "   - Example: In a clinical trial, you compare the effects of a new drug to a placebo and two other existing drugs on a primary outcome. After ANOVA shows significance, you use the Bonferroni correction to protect against Type I errors when comparing the four possible pairs.\n",
    "\n",
    "3. **Dunnett's Test**:\n",
    "   - When to Use: Dunnett's test is appropriate when you have a control group and want to compare other groups to the control group while controlling for familywise error.\n",
    "   - Example: In a study comparing the effectiveness of multiple marketing strategies, you have a control group (no marketing) and several experimental groups. You want to determine which, if any, of the experimental groups perform significantly better than the control group.\n",
    "\n",
    "4. **Sidak Correction**:\n",
    "   - When to Use: Sidak correction is another method for controlling the familywise error rate in multiple comparisons, similar to Bonferroni.\n",
    "   - Example: In a scientific experiment, you compare multiple conditions to a control group. After ANOVA reveals significant differences, you use Sidak's method to adjust the significance level for pairwise comparisons.\n",
    "\n",
    "5. **Fisher's Least Significant Difference (LSD)**:\n",
    "   - When to Use: Fisher's LSD is an older post-hoc test and is less conservative than Tukey's HSD. It can be used when you have a small number of comparisons and do not need to control the familywise error rate strictly.\n",
    "   - Example: In a psychology experiment, you compare the performance of three different age groups on a cognitive task. Fisher's LSD can be used to identify which age groups differ significantly from each other.\n",
    "\n",
    "6. **Scheffé's Test**:\n",
    "   - When to Use: Scheffé's test is suitable when you have a complex experimental design and want to control the familywise error rate for all possible pairwise comparisons.\n",
    "   - Example: In a research study involving a three-way ANOVA, you want to examine interactions between multiple factors. Scheffé's test can be used to compare specific combinations of factors.\n",
    "\n",
    "7. **Games-Howell**:\n",
    "   - When to Use: Games-Howell is a post-hoc test used when the assumptions of homogeneity of variances and equal sample sizes are violated, making Tukey's HSD less appropriate.\n",
    "   - Example: In an educational study, you compare the performance of students from different schools, but the variances in test scores are not equal across schools. Games-Howell can be used in this scenario.\n",
    "\n",
    "The choice of post-hoc test depends on the specific nature of your data and research design. It's essential to select the test that aligns with your research question and to report the post-hoc tests used in your analysis to ensure transparency and proper interpretation of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b42be-0775-4eae-b0fc-e89ae73c2388",
   "metadata": {},
   "source": [
    "# Answer 9:  \n",
    "A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e100fc3-14bf-449d-8b96-eb891f1ab906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 364.91849329644754\n",
      "p-value: 2.0742963525245934e-38\n",
      "The one-way ANOVA is statistically significant.\n",
      "There are significant differences in mean weight loss between at least two of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample weight loss data for each diet group\n",
    "diet_A = [2.5, 3.1, 3.2, 2.8, 2.9, 3.5, 3.0, 2.7, 3.3, 2.6, 2.9, 3.1, 3.4, 2.8, 3.0, 2.7, 3.2, 3.3, 2.6, 3.1, 3.0, 2.8, 2.9, 3.5, 3.2]\n",
    "diet_B = [2.0, 2.2, 2.5, 1.9, 2.3, 2.4, 2.1, 2.2, 2.0, 2.3, 2.4, 2.1, 2.5, 1.9, 2.3, 2.4, 2.2, 2.0, 2.3, 2.1, 2.2, 2.0, 2.4, 2.3, 2.1]\n",
    "diet_C = [1.0, 0.8, 1.2, 1.5, 1.3, 1.1, 1.6, 1.2, 1.3, 1.0, 1.5, 1.4, 1.1, 1.2, 1.3, 1.0, 1.4, 1.5, 1.2, 1.6, 1.0, 1.1, 1.3, 1.4, 1.5]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"There are significant differences in mean weight loss between at least two of the three diets.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"There is no evidence of significant differences in mean weight loss between the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ca5d0-1330-46d4-be14-aac9141d2582",
   "metadata": {},
   "source": [
    "# Answer 10:\n",
    "A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfdb634-6dea-4596-a2cc-3bd40032ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq    df         F    PR(>F)\n",
      "Program              1.035327   2.0  0.136986  0.872659\n",
      "Experience           0.521940   1.0  0.138118  0.713420\n",
      "Program:Experience   2.683910   2.0  0.355113  0.704716\n",
      "Residual            90.694755  24.0       NaN       NaN\n",
      "There is no significant main effect of software program.\n",
      "There is no significant main effect of employee experience.\n",
      "There is no significant interaction effect between software program and employee experience.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n = 30\n",
    "\n",
    "# Software program (3 levels: A, B, C)\n",
    "programs = np.random.choice(['A', 'B', 'C'], n)\n",
    "\n",
    "# Employee experience (2 levels: novice, experienced)\n",
    "experience = np.random.choice(['novice', 'experienced'], n)\n",
    "\n",
    "# Simulated task completion times\n",
    "completion_times = np.random.normal(10, 2, n)  # Mean of 10 minutes and standard deviation of 2 minutes\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Program': programs, 'Experience': experience, 'Time': completion_times})\n",
    "\n",
    "# Perform a two-way ANOVA\n",
    "model = ols('Time ~ Program * Experience', data=data).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "# Report the results\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Check for main effects\n",
    "p_program = anova_table.loc['Program', 'PR(>F)']\n",
    "p_experience = anova_table.loc['Experience', 'PR(>F)']\n",
    "\n",
    "if p_program < alpha:\n",
    "    print(\"There is a significant main effect of software program (A, B, C).\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of software program.\")\n",
    "\n",
    "if p_experience < alpha:\n",
    "    print(\"There is a significant main effect of employee experience (novice vs. experienced).\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of employee experience.\")\n",
    "\n",
    "# Check for interaction effect\n",
    "p_interaction = anova_table.loc['Program:Experience', 'PR(>F)']\n",
    "\n",
    "if p_interaction < alpha:\n",
    "    print(\"There is a significant interaction effect between software program and employee experience.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between software program and employee experience.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2dd33-96e6-4de2-be6c-1bee1a2ba145",
   "metadata": {},
   "source": [
    "# Answer 11: \n",
    "An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ecc15e-a07c-46a2-af1b-f393c726abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -4.108723928204809\n",
      "P-value: 8.261945608702611e-05\n",
      "The two-sample t-test is statistically significant.\n",
      "There is a significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated test scores for the control and experimental groups\n",
    "np.random.seed(42)  # For reproducibility\n",
    "control_group_scores = np.random.normal(70, 10, 50)  # Control group with a mean of 70 and std. deviation of 10\n",
    "experimental_group_scores = np.random.normal(75, 10, 50)  # Experimental group with a mean of 75 and std. deviation of 10\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Report the results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The two-sample t-test is statistically significant.\")\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"The two-sample t-test is not statistically significant.\")\n",
    "    print(\"There is no evidence of a significant difference in test scores between the groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b822ff-c225-40a8-8282-9cd5c0c710c4",
   "metadata": {},
   "source": [
    "# Answer 12: \n",
    "A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8abcca-6909-45e1-8b32-79d10183fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA results:\n",
      "F-statistic: 4.032566462057615\n",
      "p-value: 0.02114280908786695\n",
      "The one-way ANOVA is statistically significant.\n",
      "There are significant differences in daily sales between at least two of the three stores.\n",
      "\n",
      "Tukey's HSD post-hoc results:\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "     A      B   23.955 0.1297  -5.2645 53.1746  False\n",
      "     A      C   -9.884    0.7 -39.1036 19.3356  False\n",
      "     B      C  -33.839  0.019 -63.0586 -4.6195   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Simulated daily sales data for three stores (Store A, B, and C) for 30 days\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_days = 30\n",
    "n_stores = 3\n",
    "\n",
    "store_A_sales = np.random.normal(500, 50, n_days)\n",
    "store_B_sales = np.random.normal(520, 45, n_days)\n",
    "store_C_sales = np.random.normal(480, 55, n_days)\n",
    "\n",
    "# Combine data into a single DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Store': ['A'] * n_days + ['B'] * n_days + ['C'] * n_days,\n",
    "    'Sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales])\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(\n",
    "    store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "# Report the results\n",
    "print(\"One-way ANOVA results:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"There are significant differences in daily sales between at least two of the three stores.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"There is no evidence of significant differences in daily sales between the stores.\")\n",
    "\n",
    "# Perform post-hoc Tukey's HSD test for pairwise comparisons\n",
    "posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'], alpha=0.05)\n",
    "\n",
    "print(\"\\nTukey's HSD post-hoc results:\")\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638e595-2fe1-4617-a178-1ea40ea1f2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
